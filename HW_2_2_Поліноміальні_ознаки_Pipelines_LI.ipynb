{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ2A6t3mdEed"
      },
      "source": [
        "В цьому домашньому завданні ми проведемо додаткові експерименти для рішення задачі бінарної класифікації і створимо ваш новий submission на змагання на Kaggle.\n",
        "\n",
        "-----------\n",
        "\n",
        "\n",
        "**Завдання 0**. Завантажте дані `train.csv`, `test.csv`, `sample_submission.csv` зі змагання на Kaggle - шукайте посилання в уроці [Запрошення до участі у Kaggle-змаганні.](https://data-loves.kwiga.com/courses/machine-learning-dlia-liudei/domashnie-zavdannia-zmagannia-z-kaggle)  Для завантаження потрібно долучитись до змагання (натиснути кнопку \"Join\").\n",
        "\n",
        "\n",
        "**Завдання 1**. **Збираємо весь код з попереднього ДЗ в одному місці.** В лекційному ноутбуці `Логістична регресія з ScikitLearn. Повна ML задача.ipynb` ми познайомились з поняттям пайплайнів, а також я показала, як компактно виглядає рішення МЛ задачі, якщо ми зберемо весь код разом.\n",
        "\n",
        "Оскільки ми далі будемо робити експерименти, які включають ті самі етапи попередньої обробки, але інше моделювання - буде зручно мати весь код компактно і під рукою. Тому зараз ми займемось збором коду до купи :) Після цього завдання для подальших експериментів ви можете перенести частини розвʼязку взагалі в окремий `.py` файл, аби було зручно імпортувати функції.\n",
        "\n",
        "Зі свого рішення в попередньому домашньому завданні (`Логістична регресія з scikit learn.ipynb`) зберіть усі кроки розвʼязку задачі разом з використанням `sklearn.Pipeline` за прикладом з лекції.\n",
        "\n",
        "Ваш код нижче має містити\n",
        "1. Читання даних з файлу (поза пайплайном).\n",
        "2. Розбиття на тренувальний і валідаційний набори, де валідаційний містить 20% даних (поза пайплайном).\n",
        "3. Виділення категоріальних і числових колонок (поза пайплайном).\n",
        "4. Підготовку категоріальних і числових колонок (частина пайплайну). В прикладі в лекції ми оформлювали обробку числових і категоріальних колонок в окремі трансформери `numeric_transformer`, `categorical_cols`. Рекоемндую зробити саме так, так потім зручніше вносити зміни :)\n",
        "5. Тренування лог регресії (частина пайплайну).\n",
        "6. Запуск пайплайну на тренування на трен. даних (поза пайплайном).\n",
        "7. Запуск пайплайну на передбачення на трен і вал. даних і вимір метрик якості ROC-AUC + вивдення Confusion Matrix (поза пайплайном).\n",
        "8. Збереження моделі в формат joblib (поза пайплайном).\n",
        "\n",
        "Ви це все вже зробили в попереднтьому ДЗ! Тож, тут просто заадча все зібрати разом.\n",
        "\n",
        "Нижче я додала підказки, що покроково ви маєте зробити. Якщо ви почуваєтесь впевнено, можете видалити ці підказки і реалізувати все самостійно, або ж - просто заповнити пропуски.\n",
        "\n",
        "Завдання оцінюється в 10 балів. Головний результат - аби код в фіналі був робочий. Бо за не робочий нам гроші ніхто не заплатить :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 0\n",
        "import opendatasets as od\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.metrics import f1_score, confusion_matrix, roc_curve, auc\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "import operator\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.metrics import root_mean_squared_error\n",
        "from sklearn.linear_model import Ridge, Lasso, ElasticNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Завантажуємо датасет\n",
        "dataset_url= 'https://www.kaggle.com/competitions/bank-customer-churn-prediction-dlu-course-c-3/data'\n",
        "od.download(dataset_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LZialdo4IPZ"
      },
      "outputs": [],
      "source": [
        "# Зчитуємо із файлів, поділяємо датасет на тренувальний і валідаційний набори\n",
        "data_dir = 'bank-customer-churn-prediction-dlu-course-c-3'\n",
        "raw_train = pd.read_csv(data_dir + '/train.csv', index_col=0)\n",
        "raw_test = pd.read_csv(data_dir + '/test.csv')\n",
        "\n",
        "train_df, val_df = train_test_split(raw_train, test_size=0.20, random_state=42)\n",
        "\n",
        "# Визначаємо список ознак і цільової змінної, виділяємо цільову із датасета\n",
        "input_cols = list(train_df.columns)[1:-1]\n",
        "target_col = 'Exited'\n",
        "train_inputs, train_targets = train_df[input_cols], train_df[target_col]\n",
        "val_inputs, val_targets = val_df[input_cols], val_df[target_col]\n",
        "\n",
        "# Виявляємо числові і категоріальні колонки\n",
        "numeric_cols_raw = train_inputs.select_dtypes(include=np.number).columns.tolist()\n",
        "categorical_cols_raw = train_inputs.select_dtypes(include='object').columns.tolist()\n",
        "non_use_col = ['Surname'] # Визначаємо ознаки, які не будемо використовувати\n",
        "numeric_cols = [item for item in numeric_cols_raw if item not in non_use_col] # Визначаємо чисельні ознаки без невикористовуємих\n",
        "categorical_cols = [item for item in categorical_cols_raw if item not in non_use_col] # Визначаємо категоріальні ознаки без невикористовуємих\n",
        "\n",
        "'''# Обробляємо деякі колонки\n",
        "input_cols.append('Balance_codes')\n",
        "train_inputs['Balance_codes'] = train_inputs['Balance'].map(lambda x: 0 if x==0 else 1) # Додамо бінарну числову ознаку - є залишок грошей на балансі чи ні.\n",
        "val_inputs['Balance_codes'] = val_inputs['Balance'].map(lambda x: 0 if x==0 else 1)\n",
        "'''\n",
        "\n",
        "# Створюємо трансформери для числових і категоріальних колонок\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', MinMaxScaler())\n",
        "])\n",
        "\n",
        "numeric_transformer_poly2 = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', MinMaxScaler()),\n",
        "    ('polynomial_features', PolynomialFeatures(degree=2))\n",
        "])\n",
        "\n",
        "numeric_transformer_poly4 = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', MinMaxScaler()),\n",
        "    ('polynomial_features', PolynomialFeatures(degree=4))\n",
        "])\n",
        "\n",
        "numeric_transformer_poly5 = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', MinMaxScaler()),\n",
        "    ('polynomial_features', PolynomialFeatures(degree=5))\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Комбінуємо трансформери для різних типів колонок в один препроцесор\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ])\n",
        "\n",
        "preprocessor_poly2 = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer_poly2, numeric_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ])\n",
        "\n",
        "preprocessor_poly4 = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer_poly4, numeric_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ])\n",
        "\n",
        "preprocessor_poly5 = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer_poly5, numeric_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ])\n",
        "\n",
        "# Стоврюємо пайплайн, який спочатку запускає препроцесинг, потім тренуєм модель\n",
        "model_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression(solver='liblinear', class_weight={0: 1, 1: 4})) # Додаємо ваги для класів\n",
        "])\n",
        "\n",
        "model_pipeline_poly2 = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor_poly2),\n",
        "    ('classifier', LogisticRegression(solver='liblinear', class_weight={0: 1, 1: 4})) # Додаємо ваги для класів\n",
        "])\n",
        "\n",
        "model_pipeline_poly4 = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor_poly4),\n",
        "    ('classifier', LogisticRegression(solver='liblinear', class_weight={0: 1, 1: 4})) # Додаємо ваги для класів\n",
        "])\n",
        "\n",
        "model_pipeline_poly5 = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor_poly5),\n",
        "    ('classifier', LogisticRegression(solver='liblinear', class_weight={0: 1, 1: 4})) # Додаємо ваги для класів\n",
        "])\n",
        "\n",
        "# Тренуємо пайплайн\n",
        "model_pipeline.fit(train_inputs, train_targets)\n",
        "model_pipeline_poly2.fit(train_inputs, train_targets)\n",
        "model_pipeline_poly4.fit(train_inputs, train_targets)\n",
        "model_pipeline_poly5.fit(train_inputs, train_targets)\n",
        "\n",
        "# Функція, щоб передбачати і рахувати метрики\n",
        "def predict_and_plot(model_pipeline, inputs, targets, name=''):\n",
        "    preds = model_pipeline.predict(inputs)\n",
        "    fpr, tpr, _ = roc_curve(targets, preds)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(f\"Area under ROC score on {name} dataset: {roc_auc:.2f}%\")\n",
        "    confusion_matrix_ = confusion_matrix(targets, preds, normalize='true')\n",
        "    plt.figure()\n",
        "    sns.heatmap(confusion_matrix_, annot=True, cmap='Blues')\n",
        "    plt.xlabel('Prediction')\n",
        "    plt.ylabel('Target')\n",
        "    plt.title('{} Confusion Matrix'.format(name))\n",
        "    plt.show()\n",
        "    return preds\n",
        "\n",
        "# Оцінюємо модель на трен і вал даних\n",
        "train_preds = predict_and_plot(model_pipeline, train_inputs, train_targets, 'Train')\n",
        "val_preds = predict_and_plot(model_pipeline, val_inputs, val_targets, 'Validation')\n",
        "\n",
        "'''# Оцінюємо модель з поліноміальними фічами - в п.3\n",
        "train_preds = predict_and_plot(model_pipeline_poly, train_inputs, train_targets, 'Train')\n",
        "val_preds = predict_and_plot(model_pipeline_poly, val_inputs, val_targets, 'Validation')\n",
        "'''\n",
        "# Зберігаємо модель для подальшого використання\n",
        "joblib.dump(model_pipeline, 'log_reg.joblib')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXrc2NCa5lAK"
      },
      "source": [
        "**Завдання 2**. Такс, у нас з вами є вже готовий пайплайн. Давайте проведемо нові експерименти.\n",
        "\n",
        "  Додайте в попередню обробку числових колонок генерацію polinomal features до степені 2 включно. Для цього створіть новий препроцесор і створіть новий пайплайн.\n",
        "\n",
        "  Запустіть пайплайн на тренування і виведіть метрики для тренувального і валідаційного набору. Напишіть, як вам модель? Чи спостерігається в цій моделі overfit чи underfit? Чи ця модель добре генералізує?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Оцінюємо модель з поліноміальними фічами\n",
        "train_preds = predict_and_plot(model_pipeline_poly2, train_inputs, train_targets, 'Train')\n",
        "val_preds = predict_and_plot(model_pipeline_poly2, val_inputs, val_targets, 'Validation')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Модель стала краще - збільшився AUC, при цьому метрики тренувального та валідаційного наборів як і раніше, схожі. Тому можемо зробити висновок, що немає ні оверфіту, ні андерфіту. Модель генералізує гарно."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkmEmHaP8Pen"
      },
      "source": [
        "**Завдання 3**. Тепер давайте створимо ще новий пайплайн, тільки тепер поліноміальні ознаки згенеруємо до степені 4. Зробіть висновок про якість моделі. Якщо вам подобається резульат якоїсь з моделей в цьому ДЗ - рекомендую зробити submission в змаганні."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsT-MDWuOkDY"
      },
      "outputs": [],
      "source": [
        "# degree_poly = 4\n",
        "# Оцінюємо модель з поліноміальними фічами\n",
        "train_preds = predict_and_plot(model_pipeline_poly4, train_inputs, train_targets, 'Train')\n",
        "val_preds = predict_and_plot(model_pipeline_poly4, val_inputs, val_targets, 'Validation')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "У степеню 4 покращилась метрика AUC тренувального набору - 0,86, аде для валідаційного залишилась як і раніше. Можно говорити про overfit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Спробуємо поліноміалі фічі 2-го порядка на змаганні\n",
        "sample_submission_csv = data_dir + '/sample_submission.csv'\n",
        "sample_submission = pd.read_csv(sample_submission_csv)\n",
        "sample_submission.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "raw_test['Exited'] = model_pipeline_poly2.predict(raw_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_submission['Exited'] = sample_submission['id'].map(raw_test.set_index('id')['Exited'])\n",
        "sample_submission.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_submission.to_csv('D:/DS_UA/2_2 Logistic regression/HW/submission_log_reg.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozN2ONZGCBS6"
      },
      "source": [
        "**Завдання 4. Перенавчання і регуляризація**.\n",
        "\n",
        "  Скачайте набір даних `regression_data.csv`. Звичайте набір даних з `regression_data.csv`, розбийте на train і test (в тест 20%) і натренуйте модель лінійної регресії з масштабуванням числових ознак і поліноміальними ознаками до степені **5 включно**.\n",
        "\n",
        "  Виміряйте якість прогностичної моделі і зробіть висновок, чи модель хороша, чи вона добре генералізує?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xbl0jQ3WOlgn"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.190339</td>\n",
              "      <td>-1.382800</td>\n",
              "      <td>-0.875618</td>\n",
              "      <td>0.538910</td>\n",
              "      <td>-1.037246</td>\n",
              "      <td>28.938854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.321386</td>\n",
              "      <td>-0.563725</td>\n",
              "      <td>0.412931</td>\n",
              "      <td>-0.147057</td>\n",
              "      <td>-0.825497</td>\n",
              "      <td>-7.664581</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   feature_1  feature_2  feature_3  feature_4  feature_5     target\n",
              "0  -0.190339  -1.382800  -0.875618   0.538910  -1.037246  28.938854\n",
              "1  -0.321386  -0.563725   0.412931  -0.147057  -0.825497  -7.664581"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_regression = pd.read_csv('regression_data.csv')\n",
        "raw_regression.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = raw_regression.drop(['target'], axis=1)\n",
        "y = raw_regression['target']\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_lin_vs_poly_reg_and_plot(X_train, X_val, y_train, y_val, degree):\n",
        "  # Звичайна лінійна регресія\n",
        "  lin_reg = LinearRegression()\n",
        "  lin_reg.fit(X_train, y_train)\n",
        "  y_pred_train_lin = lin_reg.predict(X_train)\n",
        "  y_pred_val_lin = lin_reg.predict(X_val)\n",
        "\n",
        "  # Поліноміальна регресія\n",
        "  poly_features = PolynomialFeatures(degree=degree)\n",
        "  X_train_poly = poly_features.fit_transform(X_train)\n",
        "  X_val_poly = poly_features.transform(X_val)\n",
        "\n",
        "  print(f'В оригіналній матриці Х {X.shape[1]} ознак.')\n",
        "  print(f'В матриці Х з поліноміальними ознаками {X_train_poly.shape[1]} ознак.\\n')\n",
        "\n",
        "  poly_reg = LinearRegression()\n",
        "  poly_reg.fit(X_train_poly, y_train)\n",
        "  y_pred_train_poly = poly_reg.predict(X_train_poly)\n",
        "  y_pred_val_poly = poly_reg.predict(X_val_poly)\n",
        "\n",
        "  # Оцінка моделей\n",
        "\n",
        "  rmse_lin_train = root_mean_squared_error(y_pred_train_lin, y_train)\n",
        "  rmse_poly_train = root_mean_squared_error(y_pred_train_poly, y_train)\n",
        "\n",
        "  rmse_lin_val = root_mean_squared_error(y_pred_val_lin, y_val)\n",
        "  rmse_poly_val = root_mean_squared_error(y_pred_val_poly, y_val)\n",
        "\n",
        "\n",
        "  print(f\"Train RMSE for Linear Regression: {np.sqrt(rmse_lin_train):.3f}\")\n",
        "  print(f\"Validation RMSE for Linear Regression: {np.sqrt(rmse_lin_val):.3f}\\n\")\n",
        "\n",
        "  print(f\"Train RMSE for Polynomial Regression (degree {degree}): {np.sqrt(rmse_poly_train):.3f}\")\n",
        "  print(f\"Validation RMSE for Polynomial Regression (degree {degree}): {np.sqrt(rmse_poly_val):.3f}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "degree= 2\n",
            "В оригіналній матриці Х 5 ознак.\n",
            "В матриці Х з поліноміальними ознаками 21 ознак.\n",
            "\n",
            "Train RMSE for Linear Regression: 1.033\n",
            "Validation RMSE for Linear Regression: 0.940\n",
            "\n",
            "Train RMSE for Polynomial Regression (degree 2): 1.008\n",
            "Validation RMSE for Polynomial Regression (degree 2): 1.007\n",
            "\n",
            "degree= 3\n",
            "В оригіналній матриці Х 5 ознак.\n",
            "В матриці Х з поліноміальними ознаками 56 ознак.\n",
            "\n",
            "Train RMSE for Linear Regression: 1.033\n",
            "Validation RMSE for Linear Regression: 0.940\n",
            "\n",
            "Train RMSE for Polynomial Regression (degree 3): 0.894\n",
            "Validation RMSE for Polynomial Regression (degree 3): 1.384\n",
            "\n",
            "degree= 4\n",
            "В оригіналній матриці Х 5 ознак.\n",
            "В матриці Х з поліноміальними ознаками 126 ознак.\n",
            "\n",
            "Train RMSE for Linear Regression: 1.033\n",
            "Validation RMSE for Linear Regression: 0.940\n",
            "\n",
            "Train RMSE for Polynomial Regression (degree 4): 0.000\n",
            "Validation RMSE for Polynomial Regression (degree 4): 4.390\n",
            "\n",
            "degree= 5\n",
            "В оригіналній матриці Х 5 ознак.\n",
            "В матриці Х з поліноміальними ознаками 252 ознак.\n",
            "\n",
            "Train RMSE for Linear Regression: 1.033\n",
            "Validation RMSE for Linear Regression: 0.940\n",
            "\n",
            "Train RMSE for Polynomial Regression (degree 5): 0.000\n",
            "Validation RMSE for Polynomial Regression (degree 5): 5.425\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for degree in range(2,6):\n",
        "    print('degree=', degree)\n",
        "    train_lin_vs_poly_reg_and_plot(X_train, X_val, y_train, y_val, degree)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "В оригінальній моделі спостерігається незначний underfit - RMSE валідаційного набора нижче, на поліномі 2 ступеня найкращий результат - RMSE приблизно однакові, а ось далі зі збільшенням ступеня полінома починається overfit. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNUt-Q6UHkn7"
      },
      "source": [
        "**Завдання 5**. Натренуйте моделі Lasso(), Ridge(), ElasaticNet() на цих даних (з поліном ознаками до степені 20 включно), порівняйте якість з тою, яка була отримана з лінійною регресією. Яка модель найкраще генералізує і чому на ваш погляд (можливо треба буде для відповіді зробити додатковий аналіз ознак)?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "y93ItPYdOnpE"
      },
      "outputs": [],
      "source": [
        "models = [\n",
        "    LinearRegression(),\n",
        "    Ridge(),\n",
        "    Lasso(),\n",
        "    ElasticNet(),\n",
        "    ElasticNet(alpha=0.5)\n",
        "]\n",
        "\n",
        "def evaluate_model(model, X_train, y_train, X_val, y_val):\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_val_pred = model.predict(X_val)\n",
        "\n",
        "    train_metrics = round(root_mean_squared_error(y_train_pred, y_train),2)\n",
        "    val_metrics = round(root_mean_squared_error(y_val_pred, y_val),2)\n",
        "\n",
        "    return dict(train=train_metrics, val=val_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "degree= 2\n",
            "LinearRegression(): {'train': 1.02, 'val': 1.01}\n",
            "\n",
            "Ridge(): {'train': 1.17, 'val': 1.23}\n",
            "\n",
            "Lasso(): {'train': 1.57, 'val': 1.51}\n",
            "\n",
            "ElasticNet(): {'train': 17.39, 'val': 20.76}\n",
            "\n",
            "ElasticNet(alpha=0.5): {'train': 10.98, 'val': 13.21}\n",
            "\n",
            "degree= 3\n",
            "LinearRegression(): {'train': 0.8, 'val': 1.92}\n",
            "\n",
            "Ridge(): {'train': 1.81, 'val': 7.88}\n",
            "\n",
            "Lasso(): {'train': 1.87, 'val': 1.94}\n",
            "\n",
            "ElasticNet(): {'train': 12.41, 'val': 19.29}\n",
            "\n",
            "ElasticNet(alpha=0.5): {'train': 9.91, 'val': 20.44}\n",
            "\n",
            "degree= 4\n",
            "LinearRegression(): {'train': 0.0, 'val': 19.27}\n",
            "\n",
            "Ridge(): {'train': 1.54, 'val': 27.1}\n",
            "\n",
            "Lasso(): {'train': 1.88, 'val': 2.02}\n",
            "\n",
            "ElasticNet(): {'train': 11.61, 'val': 17.54}\n",
            "\n",
            "ElasticNet(alpha=0.5): {'train': 9.15, 'val': 15.88}\n",
            "\n",
            "degree= 5\n",
            "LinearRegression(): {'train': 0.0, 'val': 29.43}\n",
            "\n",
            "Ridge(): {'train': 1.26, 'val': 29.49}\n",
            "\n",
            "Lasso(): {'train': 1.95, 'val': 2.37}\n",
            "\n",
            "ElasticNet(): {'train': 11.66, 'val': 43.16}\n",
            "\n",
            "ElasticNet(alpha=0.5): {'train': 8.59, 'val': 34.96}\n",
            "\n",
            "degree= 6\n",
            "LinearRegression(): {'train': 0.0, 'val': 63.49}\n",
            "\n",
            "Ridge(): {'train': 1.24, 'val': 98.6}\n",
            "\n",
            "Lasso(): {'train': 1.95, 'val': 2.34}\n",
            "\n",
            "ElasticNet(): {'train': 11.2, 'val': 22.35}\n",
            "\n",
            "ElasticNet(alpha=0.5): {'train': 8.39, 'val': 21.02}\n",
            "\n",
            "degree= 7\n",
            "LinearRegression(): {'train': 0.0, 'val': 124.41}\n",
            "\n",
            "Ridge(): {'train': 1.24, 'val': 90.9}\n",
            "\n",
            "Lasso(): {'train': 2.02, 'val': 9.2}\n",
            "\n",
            "ElasticNet(): {'train': 10.52, 'val': 37.48}\n",
            "\n",
            "ElasticNet(alpha=0.5): {'train': 7.93, 'val': 39.98}\n",
            "\n",
            "degree= 8\n",
            "LinearRegression(): {'train': 0.0, 'val': 179.04}\n",
            "\n",
            "Ridge(): {'train': 1.25, 'val': 313.25}\n",
            "\n",
            "Lasso(): {'train': 2.08, 'val': 10.02}\n",
            "\n",
            "ElasticNet(): {'train': 10.43, 'val': 69.37}\n",
            "\n",
            "ElasticNet(alpha=0.5): {'train': 7.88, 'val': 61.74}\n",
            "\n",
            "degree= 9\n",
            "LinearRegression(): {'train': 0.0, 'val': 572.72}\n",
            "\n",
            "Ridge(): {'train': 1.25, 'val': 390.98}\n",
            "\n",
            "Lasso(): {'train': 2.17, 'val': 19.03}\n",
            "\n",
            "ElasticNet(): {'train': 10.22, 'val': 60.79}\n",
            "\n",
            "ElasticNet(alpha=0.5): {'train': 7.8, 'val': 121.14}\n",
            "\n",
            "degree= 10\n",
            "LinearRegression(): {'train': 0.0, 'val': 554.96}\n",
            "\n",
            "Ridge(): {'train': 1.26, 'val': 995.72}\n",
            "\n",
            "Lasso(): {'train': 2.19, 'val': 26.87}\n",
            "\n",
            "ElasticNet(): {'train': 10.24, 'val': 143.83}\n",
            "\n",
            "ElasticNet(alpha=0.5): {'train': 7.82, 'val': 142.77}\n",
            "\n",
            "degree= 11\n",
            "LinearRegression(): {'train': 0.0, 'val': 2375.79}\n",
            "\n",
            "Ridge(): {'train': 1.26, 'val': 1679.4}\n",
            "\n",
            "Lasso(): {'train': 2.24, 'val': 36.03}\n",
            "\n",
            "ElasticNet(): {'train': 10.17, 'val': 264.99}\n",
            "\n",
            "ElasticNet(alpha=0.5): {'train': 7.76, 'val': 253.1}\n",
            "\n",
            "degree= 12\n",
            "LinearRegression(): {'train': 0.0, 'val': 1665.49}\n",
            "\n",
            "Ridge(): {'train': 1.26, 'val': 3090.12}\n",
            "\n",
            "Lasso(): {'train': 2.26, 'val': 59.32}\n",
            "\n",
            "ElasticNet(): {'train': 10.18, 'val': 204.1}\n",
            "\n",
            "ElasticNet(alpha=0.5): {'train': 7.77, 'val': 270.47}\n",
            "\n",
            "degree= 13\n",
            "LinearRegression(): {'train': 0.0, 'val': 9115.98}\n",
            "\n",
            "Ridge(): {'train': 1.26, 'val': 6471.34}\n",
            "\n",
            "Lasso(): {'train': 2.29, 'val': 61.34}\n",
            "\n",
            "ElasticNet(): {'train': 10.15, 'val': 350.82}\n",
            "\n",
            "ElasticNet(alpha=0.5): {'train': 7.74, 'val': 339.57}\n",
            "\n",
            "degree= 14\n",
            "LinearRegression(): {'train': 0.0, 'val': 4514.94}\n",
            "\n",
            "Ridge(): {'train': 1.27, 'val': 9122.11}\n",
            "\n",
            "Lasso(): {'train': 2.29, 'val': 72.99}\n",
            "\n",
            "ElasticNet(): {'train': 10.16, 'val': 370.59}\n",
            "\n",
            "ElasticNet(alpha=0.5): {'train': 7.75, 'val': 376.59}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "for init in range(2,15):\n",
        "    print('degree=', init)\n",
        "    poly_features = PolynomialFeatures(degree=init)\n",
        "    X_train_poly = poly_features.fit_transform(X_train)\n",
        "    X_val_poly = poly_features.transform(X_val)\n",
        "\n",
        "    for model in models:\n",
        "        model.fit(X_train_poly, y_train)\n",
        "        eval_results  = evaluate_model(model, X_train_poly, y_train, X_val_poly, y_val)\n",
        "        print(f'{str(model)}: {eval_results}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Найкраще всіх генералізує лінійна регресія з поліномом 2 ступеню. Модель проста, але в поліномі 21 ознака, тому є сенс проаналізувати їх."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ds_ua.venv (3.12.10)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
